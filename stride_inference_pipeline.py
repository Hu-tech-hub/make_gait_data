#!/usr/bin/env python3
"""
Stride Inference Pipeline
ë¼ë²¨ë§ëœ IMU ë°ì´í„°ì—ì„œ stride cycleì„ ì¶”ì¶œí•˜ê³  í•™ìŠµëœ TCN ëª¨ë¸ë¡œ ë³´í­ ì˜ˆì¸¡

Input:
- support_labels.csv: ì§€ì§€ ë¼ë²¨ ë°ì´í„° 
- walking_data.csv: IMU ì„¼ì„œ ë°ì´í„°
- trained model: models_2/best_fold_5.keras

Process:
1. ë¼ë²¨ ë°ì´í„°ì—ì„œ stride cycle ì¶”ì¶œ
2. IMU ì„¼ì„œ ë°ì´í„°ì—ì„œ í•´ë‹¹ êµ¬ê°„ ì¶”ì¶œ
3. ë³´ì¡° íŠ¹ì„± ê³„ì‚° (stride_time, height, foot_id)
4. ì •ê·œí™” ì ìš©
5. ëª¨ë¸ ì˜ˆì¸¡
6. ê²°ê³¼ ì¶œë ¥

Author: Assistant
Date: 2025-01-12
"""

import os
import sys
import json
import numpy as np
import pandas as pd
from pathlib import Path
import tensorflow as tf
from typing import Dict, List, Tuple, Optional
import re
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# TCN ì»¤ìŠ¤í…€ ë ˆì´ì–´ë“¤ì„ ë“±ë¡í•˜ê¸° ìœ„í•´ import (ë°ì½”ë ˆì´í„° ë°©ì‹)
try:
    import tcn_model  # ë°ì½”ë ˆì´í„°ë¡œ ìë™ ë“±ë¡ë¨
    logger.info("âœ… TCN ëª¨ë¸ í´ë˜ìŠ¤ë“¤ì´ ë“±ë¡ë˜ì—ˆìŠµë‹ˆë‹¤.")
except ImportError as e:
    logger.warning(f"tcn_modelì„ importí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
    raise ImportError("TCN ëª¨ë¸ì„ ì‚¬ìš©í•˜ë ¤ë©´ tcn_model.pyê°€ í•„ìš”í•©ë‹ˆë‹¤.")


class StrideInferencePipeline:
    """Stride ê¸¸ì´ ì˜ˆì¸¡ íŒŒì´í”„ë¼ì¸"""
    
    def __init__(self, model_path="models/best_fold_5.keras", 
                 metadata_dir="metadata"):
        """
        ì´ˆê¸°í™”
        
        Args:
            model_path: í•™ìŠµëœ ëª¨ë¸ ê²½ë¡œ
            metadata_dir: ì •ê·œí™” í†µê³„ ë“± ë©”íƒ€ë°ì´í„° ë””ë ‰í† ë¦¬
        """
        # ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜
        base_dir = Path(__file__).parent
        self.model_path = base_dir / model_path if not Path(model_path).is_absolute() else Path(model_path)
        self.metadata_dir = base_dir / metadata_dir if not Path(metadata_dir).is_absolute() else Path(metadata_dir)
        self.model = None
        self.normalization_stats = None
        self.auxiliary_stats = None
        self.fps = 30.0  # ê¸°ë³¸ FPS
        
        # Subjectë³„ í‚¤ ì •ë³´ (cm)
        self.subject_heights = {
            'SA01': 175,
            'SA02': 170, 
            'SA03': 180,
            'SA04': 160,
            'SA05': 160
        }
        
        # Foot mapping
        self.foot_mapping = {'left': 0, 'right': 1}
        
    def load_model_and_stats(self):
        """ëª¨ë¸ê³¼ ì •ê·œí™” í†µê³„ ë¡œë“œ"""
        try:
            # ëª¨ë¸ ë¡œë“œ (ë°ì½”ë ˆì´í„°ë¡œ ë“±ë¡ëœ í´ë˜ìŠ¤ë“¤ì€ ìë™ìœ¼ë¡œ ì¸ì‹ë¨)
            self.model = tf.keras.models.load_model(self.model_path)
            logger.info(f"âœ… ëª¨ë¸ ë¡œë“œ ì„±ê³µ: {self.model_path}")
            logger.info("   (ë°ì½”ë ˆì´í„°ë¡œ ë“±ë¡ëœ ì»¤ìŠ¤í…€ ë ˆì´ì–´ ì‚¬ìš©)")
            
            # ì •ê·œí™” í†µê³„ ë¡œë“œ
            norm_file = self.metadata_dir / "global_norm_enhanced.npz"
            if norm_file.exists():
                norm_data = np.load(norm_file)
                
                if 'sequence_mean' in norm_data.files:
                    self.normalization_stats = {
                        'mean': norm_data['sequence_mean'],
                        'std': norm_data['sequence_std']
                    }
                    self.auxiliary_stats = {
                        'height_mean': norm_data['height_mean'],
                        'height_std': norm_data['height_std'],
                        'stride_time_mean': norm_data['stride_time_mean'],
                        'stride_time_std': norm_data['stride_time_std']
                    }
                else:
                    self.normalization_stats = {
                        'mean': norm_data['mean'],
                        'std': norm_data['std']
                    }
                    self.auxiliary_stats = {
                        'height_mean': norm_data.get('aux_height_mean', 170.0),
                        'height_std': norm_data.get('aux_height_std', 10.0),
                        'stride_time_mean': norm_data.get('aux_stride_time_mean', 1.0),
                        'stride_time_std': norm_data.get('aux_stride_time_std', 0.3)
                    }
                logger.info("âœ… ì •ê·œí™” í†µê³„ ë¡œë“œ ì„±ê³µ")
            else:
                # ê¸°ë³¸ global_norm.npz ì‹œë„
                norm_file = self.metadata_dir / "global_norm.npz"
                if norm_file.exists():
                    norm_data = np.load(norm_file)
                    
                    self.normalization_stats = {
                        'mean': norm_data['sequence_mean'],
                        'std': norm_data['sequence_std']
                    }
                    self.auxiliary_stats = {
                        'height_mean': 170.0,
                        'height_std': 10.0,
                        'stride_time_mean': 1.0,
                        'stride_time_std': 0.3
                    }
                    logger.info("âœ… ê¸°ë³¸ ì •ê·œí™” í†µê³„ ë¡œë“œ ì„±ê³µ")
                else:
                    raise FileNotFoundError(f"ì •ê·œí™” í†µê³„ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.metadata_dir}")
            
        except Exception as e:
            logger.error(f"âŒ ëª¨ë¸/í†µê³„ ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise
    
    def load_support_labels(self, labels_file: str) -> List[Dict]:
        """ì§€ì§€ ë¼ë²¨ CSV ë¡œë“œ"""
        try:
            df = pd.read_csv(labels_file)
            labels = []
            
            for _, row in df.iterrows():
                label = {
                    'start_frame': int(row['start_frame']),
                    'end_frame': int(row['end_frame']),
                    'phase': row['phase'].strip()
                }
                labels.append(label)
            
            logger.info(f"âœ… ì§€ì§€ ë¼ë²¨ ë¡œë“œ: {len(labels)}ê°œ ë¼ë²¨")
            return labels
            
        except Exception as e:
            logger.error(f"âŒ ì§€ì§€ ë¼ë²¨ ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise
    
    def load_walking_data(self, walking_file: str) -> pd.DataFrame:
        """IMU ì„¼ì„œ ë°ì´í„° ë¡œë“œ"""
        try:
            df = pd.read_csv(walking_file)
            
            # í•„ìš”í•œ ì»¬ëŸ¼ í™•ì¸
            required_cols = ['frame_number', 'sync_timestamp', 'accel_x', 'accel_y', 'accel_z', 'gyro_x', 'gyro_y', 'gyro_z']
            missing_cols = [col for col in required_cols if col not in df.columns]
            
            if missing_cols:
                raise ValueError(f"ëˆ„ë½ëœ ì»¬ëŸ¼: {missing_cols}")
            
            logger.info(f"âœ… IMU ë°ì´í„° ë¡œë“œ: {len(df)}ê°œ í”„ë ˆì„")
            return df
            
        except Exception as e:
            logger.error(f"âŒ IMU ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise
    
    def find_stride_cycles(self, labels: List[Dict], stride_type: str) -> List[Dict]:
        """
        íŠ¹ì • stride typeì˜ cycleë“¤ì„ ì°¾ê¸°
        gait_calculation_engine.pyì˜ _find_stride_cycles ì°¸ê³ 
        """
        # Phase sequence ë§¤í•‘
        phase_mapping = {
            'double_support': 'double_stance',
            'single_support_left': 'left_stance', 
            'left_support': 'left_stance',
            'single_support_right': 'right_stance',
            'right_support': 'right_stance'
        }
        
        # ë¼ë²¨ ë°ì´í„° ì •ê·œí™”
        normalized_labels = []
        for label in labels:
            phase = label.get('phase', '')
            normalized_phase = phase_mapping.get(phase, phase)
            if normalized_phase in ['double_stance', 'left_stance', 'right_stance', 'non_gait']:
                normalized_labels.append({
                    'phase': normalized_phase,
                    'start_frame': label.get('start_frame', 0),
                    'end_frame': label.get('end_frame', 0)
                })
        
        # Stride sequence ì •ì˜
        if stride_type == 'right':
            sequence = ['double_stance', 'right_stance', 'double_stance', 'left_stance']
        elif stride_type == 'left':
            sequence = ['double_stance', 'left_stance', 'double_stance', 'right_stance']
        else:
            raise ValueError(f"Invalid stride_type: {stride_type}")
        
        stride_cycles = []
        i = 0
        
        while i <= len(normalized_labels) - len(sequence):
            # í˜„ì¬ ìœ„ì¹˜ì—ì„œ ì‹œí€€ìŠ¤ê°€ ë§¤ì¹˜ë˜ëŠ”ì§€ í™•ì¸
            match = True
            sequence_labels = []
            
            for j, expected_phase in enumerate(sequence):
                if i + j >= len(normalized_labels):
                    match = False
                    break
                    
                current_label = normalized_labels[i + j]
                if current_label['phase'] != expected_phase:
                    match = False
                    break
                    
                sequence_labels.append(current_label)
            
            if match:
                # ë§¤ì¹˜ëœ ì‹œí€€ìŠ¤ ì •ë³´ ì €ì¥
                start_frame = sequence_labels[0]['start_frame']
                end_frame = sequence_labels[-1]['end_frame']
                
                stride_info = {
                    'type': stride_type,
                    'start_frame': start_frame,
                    'end_frame': end_frame,
                    'sequence': sequence_labels
                }
                
                stride_cycles.append(stride_info)
                i += 1
            else:
                i += 1
        
        logger.info(f"âœ… {stride_type} stride ë°œê²¬: {len(stride_cycles)}ê°œ")
        return stride_cycles
    
    def extract_cycle_sequence(self, walking_df: pd.DataFrame, 
                             start_frame: int, end_frame: int) -> List[List[float]]:
        """stride cycle êµ¬ê°„ì˜ ì„¼ì„œ ë°ì´í„° ì¶”ì¶œ"""
        try:
            # í”„ë ˆì„ ë²”ìœ„ í•„í„°ë§
            cycle_data = walking_df[
                (walking_df['frame_number'] >= start_frame) & 
                (walking_df['frame_number'] <= end_frame)
            ].copy()
            
            if cycle_data.empty:
                logger.warning(f"í”„ë ˆì„ ë²”ìœ„ {start_frame}-{end_frame}ì— ë°ì´í„° ì—†ìŒ")
                return []
            
            # ì„¼ì„œ ë°ì´í„° ì¶”ì¶œ
            sequence = []
            for idx, row in cycle_data.iterrows():
                try:
                    frame_data = [
                        float(row['accel_x']),
                        float(row['accel_y']),
                        float(row['accel_z']),
                        float(row['gyro_x']),
                        float(row['gyro_y']),
                        float(row['gyro_z'])
                    ]
                    
                    # ìœ íš¨ì„± ê²€ì‚¬
                    if len(frame_data) != 6 or any(not np.isfinite(val) for val in frame_data):
                        continue
                        
                    sequence.append(frame_data)
                    
                except Exception as e:
                    logger.error(f"í”„ë ˆì„ {row['frame_number']} ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                    continue
            
            if len(sequence) == 0:
                logger.error(f"ìœ íš¨í•œ í”„ë ˆì„ ì—†ìŒ: {start_frame}-{end_frame}")
                return []
            
            return sequence
            
        except Exception as e:
            logger.error(f"Cycle sequence ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return []
    
    def calculate_stride_time(self, start_frame: int, end_frame: int) -> float:
        """Stride time ê³„ì‚°"""
        return (end_frame - start_frame) / self.fps
    
    def extract_subject_id(self, filename: str) -> str:
        """íŒŒì¼ëª…ì—ì„œ subject ID ì¶”ì¶œ (S01 -> SA01)"""
        pattern = r'(S\d+)'
        match = re.search(pattern, filename)
        if match:
            subject_num = match.group(1)
            return 'SA' + subject_num[1:]  # S01 -> SA01
        return 'SA01'  # ê¸°ë³¸ê°’
    
    def get_subject_height(self, subject_id: str) -> int:
        """Subjectì˜ í‚¤ ë°˜í™˜"""
        return self.subject_heights.get(subject_id, 170)  # ê¸°ë³¸ê°’ 170cm
    
    def normalize_sequence(self, sequence: List[List[float]]) -> np.ndarray:
        """ì‹œí€€ìŠ¤ ì •ê·œí™”"""
        seq_array = np.array(sequence)
        
        if seq_array.shape != (len(sequence), 6):
            logger.warning(f"ì‹œí€€ìŠ¤ í˜•íƒœ ë¶ˆì¼ì¹˜: {seq_array.shape}")
        
        # ì„¼ì„œ ë°ì´í„° ì •ê·œí™”
        try:
            normalized = (seq_array - self.normalization_stats['mean']) / self.normalization_stats['std']
        except Exception as e:
            logger.error(f"ì •ê·œí™” ì‹¤íŒ¨: {e}")
            raise
        
        return normalized.astype(np.float32)
    
    def normalize_auxiliary_features(self, height: float, stride_time: float, foot_id: int) -> np.ndarray:
        """ë³´ì¡° íŠ¹ì„± ì •ê·œí™”"""
        # Height ì •ê·œí™”
        norm_height = (height - self.auxiliary_stats['height_mean']) / self.auxiliary_stats['height_std']
        
        # Stride time ì •ê·œí™”
        norm_stride_time = (stride_time - self.auxiliary_stats['stride_time_mean']) / self.auxiliary_stats['stride_time_std']
        
        # Foot IDëŠ” one-hot encodingëœ ìƒíƒœë¡œ ì…ë ¥ (0 or 1)
        foot_binary = float(foot_id)
        
        return np.array([norm_height, norm_stride_time, foot_binary], dtype=np.float32)
    
    def prepare_model_input(self, cycles_data: List[Dict]) -> Tuple[tf.Tensor, tf.Tensor]:
        """ëª¨ë¸ ì…ë ¥ í˜•íƒœë¡œ ë°ì´í„° ì¤€ë¹„"""
        sequences = []
        auxiliary_features = []
        
        for cycle in cycles_data:
            # ì‹œí€€ìŠ¤ ì •ê·œí™”
            normalized_seq = self.normalize_sequence(cycle['sequence'])
            sequences.append(normalized_seq)
            
            # ë³´ì¡° íŠ¹ì„± ì •ê·œí™”
            aux_features = self.normalize_auxiliary_features(
                cycle['height'], 
                cycle['stride_time'],
                cycle['foot_id']
            )
            auxiliary_features.append(aux_features)
        
        # ëª¨ë¸ì´ ê¸°ëŒ€í•˜ëŠ” ê³ ì • ê¸¸ì´ ì‚¬ìš© (í•™ìŠµ ì‹œì™€ ë™ì¼)
        MODEL_EXPECTED_LENGTH = 67
        
        # íŒ¨ë”©ëœ ì‹œí€€ìŠ¤ ìƒì„±
        padded_sequences = []
        for seq in sequences:
            if len(seq) < MODEL_EXPECTED_LENGTH:
                # 0ìœ¼ë¡œ íŒ¨ë”©
                padding_needed = MODEL_EXPECTED_LENGTH - len(seq)
                padding = np.zeros((padding_needed, 6), dtype=np.float32)
                seq_array = np.array(seq, dtype=np.float32)
                padded_seq = np.concatenate([seq_array, padding], axis=0)
            else:
                padded_seq = np.array(seq, dtype=np.float32)[:MODEL_EXPECTED_LENGTH]
                
            padded_sequences.append(padded_seq)
        
        # í…ì„œ ìƒì„±
        padded_sequences_array = np.array(padded_sequences, dtype=np.float32)
        sequence_tensor = tf.constant(padded_sequences_array, dtype=tf.float32)
        auxiliary_tensor = tf.constant(auxiliary_features, dtype=tf.float32)
        
        return sequence_tensor, auxiliary_tensor
    
    def predict_stride_lengths(self, sequences: tf.Tensor, 
                             auxiliary: tf.Tensor) -> np.ndarray:
        """ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ stride length ì˜ˆì¸¡"""
        try:
            predictions = self.model([sequences, auxiliary])
            return predictions.numpy().flatten()
            
        except Exception as e:
            logger.error(f"âŒ ëª¨ë¸ ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
            raise
    
    def process_single_session(self, labels_file: str, walking_file: str) -> Dict:
        """ë‹¨ì¼ ì„¸ì…˜ ì²˜ë¦¬"""
        logger.info(f"ì„¸ì…˜ ì²˜ë¦¬ ì‹œì‘: {Path(labels_file).stem}")
        
        try:
            # 1. ë°ì´í„° ë¡œë“œ
            support_labels = self.load_support_labels(labels_file)
            walking_df = self.load_walking_data(walking_file)
            
            # 2. Subject ì •ë³´ ì¶”ì¶œ
            subject_id = self.extract_subject_id(Path(labels_file).stem)
            height = self.get_subject_height(subject_id)
            
            logger.info(f"Subject: {subject_id}, Height: {height}cm")
            
            # 3. Stride cycles ì¶”ì¶œ
            left_cycles = self.find_stride_cycles(support_labels, 'left')
            right_cycles = self.find_stride_cycles(support_labels, 'right')
            
            all_cycles_data = []
            
            # 4. Left cycles ì²˜ë¦¬
            for i, cycle in enumerate(left_cycles):
                sequence = self.extract_cycle_sequence(
                    walking_df, cycle['start_frame'], cycle['end_frame']
                )
                
                if len(sequence) < 15:  # ìµœì†Œ ê¸¸ì´ ì²´í¬
                    logger.warning(f"Left cycle {i+1}: ì‹œí€€ìŠ¤ ê¸¸ì´ ë¶€ì¡± ({len(sequence)})")
                    continue
                
                stride_time = self.calculate_stride_time(
                    cycle['start_frame'], cycle['end_frame']
                )
                
                cycle_data = {
                    'cycle_number': len(all_cycles_data) + 1,
                    'foot': 'left',
                    'foot_id': self.foot_mapping['left'],
                    'start_frame': cycle['start_frame'],
                    'end_frame': cycle['end_frame'],
                    'sequence': sequence,
                    'height': height,
                    'stride_time': stride_time,
                    'sequence_length': len(sequence)
                }
                all_cycles_data.append(cycle_data)
            
            # 5. Right cycles ì²˜ë¦¬
            for i, cycle in enumerate(right_cycles):
                sequence = self.extract_cycle_sequence(
                    walking_df, cycle['start_frame'], cycle['end_frame']
                )
                
                if len(sequence) < 15:  # ìµœì†Œ ê¸¸ì´ ì²´í¬
                    logger.warning(f"Right cycle {i+1}: ì‹œí€€ìŠ¤ ê¸¸ì´ ë¶€ì¡± ({len(sequence)})")
                    continue
                
                stride_time = self.calculate_stride_time(
                    cycle['start_frame'], cycle['end_frame']
                )
                
                cycle_data = {
                    'cycle_number': len(all_cycles_data) + 1,
                    'foot': 'right',
                    'foot_id': self.foot_mapping['right'],
                    'start_frame': cycle['start_frame'],
                    'end_frame': cycle['end_frame'],
                    'sequence': sequence,
                    'height': height,
                    'stride_time': stride_time,
                    'sequence_length': len(sequence)
                }
                all_cycles_data.append(cycle_data)
            
            if not all_cycles_data:
                logger.warning("âš ï¸ ìœ íš¨í•œ stride cycleì´ ì—†ìŠµë‹ˆë‹¤.")
                return {
                    'subject_id': subject_id,
                    'total_cycles': 0,
                    'predictions': [],
                    'error': 'No valid cycles found'
                }
            
            # 6. ëª¨ë¸ ì…ë ¥ ì¤€ë¹„ ë° ì˜ˆì¸¡
            sequences, auxiliary = self.prepare_model_input(all_cycles_data)
            predictions = self.predict_stride_lengths(sequences, auxiliary)
            
            # 7. ê²°ê³¼ ì •ë¦¬
            results = []
            for i, (cycle_data, pred_length) in enumerate(zip(all_cycles_data, predictions)):
                result = {
                    'cycle_number': cycle_data['cycle_number'],
                    'foot': cycle_data['foot'],
                    'start_frame': cycle_data['start_frame'],
                    'end_frame': cycle_data['end_frame'],
                    'sequence_length': cycle_data['sequence_length'],
                    'stride_time': cycle_data['stride_time'],
                    'predicted_stride_length': float(pred_length),
                    'predicted_velocity': float(pred_length / cycle_data['stride_time']) if cycle_data['stride_time'] > 0 else 0.0
                }
                results.append(result)
            
            # 8. í†µê³„ ê³„ì‚°
            stride_lengths = [r['predicted_stride_length'] for r in results]
            velocities = [r['predicted_velocity'] for r in results]
            
            summary = {
                'subject_id': subject_id,
                'height': height,
                'total_cycles': len(results),
                'left_cycles': len([r for r in results if r['foot'] == 'left']),
                'right_cycles': len([r for r in results if r['foot'] == 'right']),
                'mean_stride_length': np.mean(stride_lengths),
                'std_stride_length': np.std(stride_lengths),
                'mean_velocity': np.mean(velocities),
                'std_velocity': np.std(velocities),
                'predictions': results
            }
            
            logger.info(f"ì˜ˆì¸¡ ì™„ë£Œ: {len(results)}ê°œ cycle (í‰ê·  stride: {summary['mean_stride_length']:.3f}m)")
            
            return summary
            
        except Exception as e:
            logger.error(f"âŒ ì„¸ì…˜ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return {
                'subject_id': subject_id if 'subject_id' in locals() else 'Unknown',
                'total_cycles': 0,
                'predictions': [],
                'error': str(e)
            }
    
    def save_results(self, results: Dict, output_file: str):
        """ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥"""
        try:
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(results, f, indent=2, ensure_ascii=False)
            logger.info(f"âœ… ê²°ê³¼ ì €ì¥: {output_file}")
            
        except Exception as e:
            logger.error(f"âŒ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def run_inference(self, labels_file: str, walking_file: str, 
                     output_file: Optional[str] = None) -> Dict:
        """ì „ì²´ ì¶”ë¡  íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        logger.info(f"ğŸš€ Stride Inference Pipeline ì‹œì‘")
        
        try:
            # 1. ëª¨ë¸ê³¼ í†µê³„ ë¡œë“œ
            if self.model is None:
                self.load_model_and_stats()
            
            # 2. ì„¸ì…˜ ì²˜ë¦¬
            results = self.process_single_session(labels_file, walking_file)
            
            # 3. ê²°ê³¼ ì €ì¥ (ì˜µì…˜)
            if output_file:
                self.save_results(results, output_file)
            
            logger.info(f"ğŸ‰ ì¶”ë¡  ì™„ë£Œ!")
            return results
            
        except Exception as e:
            logger.error(f"âŒ ì¶”ë¡  íŒŒì´í”„ë¼ì¸ ì‹¤íŒ¨: {e}")
            raise


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    import argparse
    
    parser = argparse.ArgumentParser(description='Stride Inference Pipeline')
    parser.add_argument('--labels', required=True, help='Support labels CSV íŒŒì¼')
    parser.add_argument('--walking', required=True, help='Walking data CSV íŒŒì¼')
    parser.add_argument('--model', default='models_2/best_fold_5.keras', help='ëª¨ë¸ íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--output', help='ê²°ê³¼ JSON íŒŒì¼ (ì˜µì…˜)')
    parser.add_argument('--metadata_dir', default='metadata', help='ë©”íƒ€ë°ì´í„° ë””ë ‰í† ë¦¬')
    
    args = parser.parse_args()
    
    # íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    pipeline = StrideInferencePipeline(args.model, args.metadata_dir)
    results = pipeline.run_inference(args.labels, args.walking, args.output)
    
    # ê°„ë‹¨í•œ ê²°ê³¼ ì¶œë ¥
    if 'error' not in results:
        print(f"\n{'='*50}")
        print(f"STRIDE INFERENCE RESULTS")
        print(f"{'='*50}")
        print(f"Subject: {results['subject_id']} (Height: {results['height']}cm)")
        print(f"Total Cycles: {results['total_cycles']}")
        print(f"Mean Stride Length: {results['mean_stride_length']:.3f} Â± {results['std_stride_length']:.3f} m")
        print(f"Mean Velocity: {results['mean_velocity']:.3f} Â± {results['std_velocity']:.3f} m/s")
        print(f"{'='*50}")


if __name__ == "__main__":
    # ì˜ˆì‹œ ì‹¤í–‰
    if len(sys.argv) == 1:
        # ê¸°ë³¸ ì˜ˆì‹œ ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸
        base_dir = Path(__file__).parent
        labels_file = str(base_dir / "support_label_data/SA01/S01T01R01_support_labels.csv")
        walking_file = str(base_dir / "walking_data/SA01/S01T01R01.csv")
        
        pipeline = StrideInferencePipeline()
        results = pipeline.run_inference(labels_file, walking_file, "inference_results.json")
    else:
        main()